<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>DenseNet -Densely Connected Convolutional Networks (CVPR 2017) ðŸ“‘</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="preload" href="../assets/css/app.css?v=decde706a5" as="style">
    <link rel="preload" href="../assets/js/manifest.js?v=decde706a5" as="script">
    <link rel="preload" href="../assets/js/vendor/content-api.min.js?v=decde706a5" as="script">
    <link rel="preload" href="../assets/js/vendor.js?v=decde706a5" as="script">
    <link rel="preload" href="../assets/js/app.js?v=decde706a5" as="script">
    <link rel="preconnect" href="https://polyfill.io">
    <link rel="dns-prefetch" href="https://polyfill.io">

      <link rel="preload" href="../assets/css/post.css?v=decde706a5" as="style">
  <link rel="preload" href="../assets/js/post.js?v=decde706a5" as="script">


    <style>
      /* These font-faces are here to make fonts work if the Ghost instance is installed in a subdirectory */

      /* source-sans-pro-regular */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'),
            url("../assets/fonts/source-sans-pro/source-sans-pro-regular.woff2?v=decde706a5") format('woff2'),
            url("../assets/fonts/source-sans-pro/source-sans-pro-regular.woff?v=decde706a5") format('woff');
      }

      /* source-sans-pro-600 */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 600;
        font-display: swap;
        src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'),
            url("../assets/fonts/source-sans-pro/source-sans-pro-600.woff2?v=decde706a5") format('woff2'),
            url("../assets/fonts/source-sans-pro/source-sans-pro-600.woff?v=decde706a5") format('woff');
      }

      /* source-sans-pro-700 */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: local('Source Sans Pro Bold'), local('SourceSansPro-Bold'),
            url("../assets/fonts/source-sans-pro/source-sans-pro-700.woff2?v=decde706a5") format('woff2'),
            url("../assets/fonts/source-sans-pro/source-sans-pro-700.woff?v=decde706a5") format('woff');
      }

      /* iconmoon */
      @font-face {
        font-family: 'icomoon';
        font-weight: normal;
        font-style: normal;
        font-display: swap;
        src: url("../assets/fonts/icomoon/icomoon.eot?aoz2mo?v=decde706a5");
        src: url("../assets/fonts/icomoon/icomoon.eot?aoz2mo") format('embedded-opentype'),
        url("../assets/fonts/icomoon/icomoon.ttf?aoz2mo?v=decde706a5") format('truetype'),
        url("../assets/fonts/icomoon/icomoon.woff?aoz2mo?v=decde706a5") format('woff'),
        url("../assets/fonts/icomoon/icomoon.svg?aoz2mo") format('svg');
      }
    </style>

    <link rel="stylesheet" type="text/css" href="../assets/css/app.css?v=decde706a5" media="screen">

      <link rel="stylesheet" type="text/css" href="../assets/css/post.css?v=decde706a5" media="screen">


    

    <link rel="icon" href="../favicon.png" type="image/png">
    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="amp/index.html">
    
    <meta property="og:site_name" content="Deep Neural Notebooks">
    <meta property="og:type" content="article">
    <meta property="og:title" content="DenseNet -Densely Connected Convolutional Networks (CVPR 2017) ðŸ“‘">
    <meta property="og:description" content="CVPR 2017, Best Paper Award winner Dense connectionsâ€œSimple models and a lot of data trump more elaborate models based on less data. â€œâ€Šâ€”â€ŠPeter NorvigAbout the paperâ€˜Densely Connected Convolutional Networksâ€™ received the Best Paper Award at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017. The paper">
    <meta property="og:url" content="http://localhost:2368/densenet-densely-connected-convolutional-networks/">
    <meta property="og:image" content="http://localhost:2368/content/images/2020/10/1_TeHVqikNc68QC98Vm9M98Q.gif">
    <meta property="article:published_time" content="2019-11-10T04:23:00.000Z">
    <meta property="article:modified_time" content="2020-10-24T06:02:00.000Z">
    <meta property="article:tag" content="8k+ views">
    <meta property="article:tag" content="Paper Review">
    <meta property="article:tag" content="Computer Vision">
    <meta property="article:tag" content="Deep Learning">
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="DenseNet -Densely Connected Convolutional Networks (CVPR 2017) ðŸ“‘">
    <meta name="twitter:description" content="CVPR 2017, Best Paper Award winner Dense connectionsâ€œSimple models and a lot of data trump more elaborate models based on less data. â€œâ€Šâ€”â€ŠPeter NorvigAbout the paperâ€˜Densely Connected Convolutional Networksâ€™ received the Best Paper Award at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017. The paper">
    <meta name="twitter:url" content="http://localhost:2368/densenet-densely-connected-convolutional-networks/">
    <meta name="twitter:image" content="http://localhost:2368/content/images/2020/10/1_TeHVqikNc68QC98Vm9M98Q.gif">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Mukul Khanna">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="8k+ views, Paper Review, Computer Vision, Deep Learning">
    <meta name="twitter:site" content="@mkulkhanna">
    <meta name="twitter:creator" content="@mkulkhanna">
    <meta property="og:image:width" content="735">
    <meta property="og:image:height" content="374">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Deep Neural Notebooks",
        "url": "http://localhost:2368/",
        "logo": {
            "@type": "ImageObject",
            "url": "http://localhost:2368/content/images/2020/07/imageonline-co-whitebackgroundremoved-2.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Mukul Khanna",
        "image": {
            "@type": "ImageObject",
            "url": "http://localhost:2368/content/images/2020/07/3CA5BB6B-761F-4F3F-8BEC-32E58969F08E-3.JPG",
            "width": 2000,
            "height": 1981
        },
        "url": "http://localhost:2368/author/mukul/",
        "sameAs": [
            "http://mukulkhanna.co",
            "https://twitter.com/mkulkhanna"
        ]
    },
    "headline": "DenseNet -Densely Connected Convolutional Networks (CVPR 2017) ðŸ“‘",
    "url": "http://localhost:2368/densenet-densely-connected-convolutional-networks/",
    "datePublished": "2019-11-10T04:23:00.000Z",
    "dateModified": "2020-10-24T06:02:00.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:2368/content/images/2020/10/1_TeHVqikNc68QC98Vm9M98Q.gif",
        "width": 735,
        "height": 374
    },
    "keywords": "8k+ views, Paper Review, Computer Vision, Deep Learning",
    "description": "CVPR 2017, Best Paper Award winner\n\nDense connections&gt; â€œSimple models and a lot of data trump more elaborate models\nbased on less data. â€œâ€Šâ€”Peter Norvig\nAbout the paper\nâ€˜Densely Connected Convolutional Networksâ€™ received the Best Paper Award at the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017. The\npaper can be read here [https://arxiv.org/pdf/1608.06993.pdf].\n\nThe primary author, Gao Huang [http://www.gaohuang.net/] has been a Postdoctoral\nFellow at Cornell University an",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368/"
    }
}
    </script>

    <meta name="generator" content="Ghost 4.2">
    <link rel="alternate" type="application/rss+xml" title="Deep Neural Notebooks" href="../rss/index.html">
    <script defer src="https://unpkg.com/@tryghost/portal@~1.1.0/umd/portal.min.js" data-ghost="http://localhost:2368/"></script><style> .gh-post-upgrade-cta-content,
.gh-post-upgrade-cta {
    display: flex;
    flex-direction: column;
    align-items: center;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    text-align: center;
    width: 100%;
    color: #ffffff;
    font-size: 16px;
}

.gh-post-upgrade-cta-content {
    border-radius: 8px;
    padding: 40px 4vw;
}

.gh-post-upgrade-cta h2 {
    color: #ffffff;
    font-size: 28px;
    letter-spacing: -0.2px;
    margin: 0;
    padding: 0;
}

.gh-post-upgrade-cta p {
    margin: 20px 0 0;
    padding: 0;
}

.gh-post-upgrade-cta small {
    font-size: 16px;
    letter-spacing: -0.2px;
}

.gh-post-upgrade-cta a {
    color: #ffffff;
    cursor: pointer;
    font-weight: 500;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a:hover {
    color: #ffffff;
    opacity: 0.8;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a.gh-btn {
    display: block;
    background: #ffffff;
    text-decoration: none;
    margin: 28px 0 0;
    padding: 8px 18px;
    border-radius: 4px;
    font-size: 16px;
    font-weight: 600;
}

.gh-post-upgrade-cta a.gh-btn:hover {
    opacity: 0.92;
}</style>
    <script>
  const ghostSearchApiKey = 'efff2b0d00118a51535099c413'
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1H8F4BQ5WV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1H8F4BQ5WV');
</script>

<!-- prism.js -->
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/themes/prism-tomorrow.min.css">

<style>
  pre[class*="language-"] {
    margin: 0 0 1.5em !important;
  }
  code {
    text-shadow: none !important;
  }
  .token.operator {
    background: none !important;
  }
  :not(pre) > code[class*="language-"],
  pre[class*="language-"] {
    background: #20262E !important;
  }

</style>
<style>:root {--ghost-accent-color: #de54ab;}</style>

    <script>
      // @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&dn=expat.txt Expat
      const ghostHost = "http://localhost:2368"
      // @license-end
    </script>
  </head>
  <body class="post-template tag-8k-views tag-paper-review tag-computer-vision tag-deep-learning">
    



  
<header class="m-header with-picture js-header">
  <div class="m-mobile-topbar" data-aos="fade-down">
    <button class="m-icon-button in-mobile-topbar js-open-menu" aria-label="Open menu">
      <span class="icon-menu" aria-hidden="true"></span>
    </button>
      <a href="../index.html" class="m-logo in-mobile-topbar">
        <img src="../content/images/2020/07/imageonline-co-whitebackgroundremoved-2.png" alt="Deep Neural Notebooks">
      </a>
    <button class="m-icon-button in-mobile-topbar js-open-search" aria-label="Open search">
      <span class="icon-search" aria-hidden="true"></span>
    </button>
  </div>

  <div class="m-menu js-menu">
    <button class="m-icon-button outlined as-close-menu js-close-menu" aria-label="Close menu">
      <span class="icon-close"></span>
    </button>
    <div class="m-menu__main" data-aos="fade-down">
      <div class="l-wrapper">
        <div class="m-nav js-main-nav">
          <nav class="m-nav__left js-main-nav-left" role="navigation" aria-label="Main menu">
            <ul>
                <li class="only-desktop">
                  <a href="../index.html" class="m-logo">
                    <img src="../content/images/2020/07/imageonline-co-whitebackgroundremoved-2.png" alt="Deep Neural Notebooks">
                  </a>
                </li>
                
    <li class="nav-mukul-khanna">
      <a href="../about/index.html">Mukul Khanna</a>
    </li>
    <li class="nav-podcast">
      <a href="../index.html">podcast</a>
    </li>
    <li class="nav-blog">
      <a href="../author/mukul/index.html">blog</a>
    </li>
    <li class="nav-youtube">
      <a href="https://www.youtube.com/channel/UC66w1T4oMv66Jn1LR5CW2yg">youtube</a>
    </li>
    <li class="nav-bf2normalnet">
      <a href="../bf2normalnet/index.html">bf2normalnet</a>
    </li>

            </ul>
          </nav>
          <div class="m-nav__right">
            <button class="m-icon-button in-menu-main js-open-search" aria-label="Open search">
              <span class="icon-search" aria-hidden="true"></span>
            </button>
            <div class="m-toggle-darkmode js-tooltip" data-tippy-content="Toggle dark mode" tabindex="0">
              <label for="toggle-darkmode" class="sr-only">
                Toggle dark mode
              </label>
              <input id="toggle-darkmode" type="checkbox" class="js-toggle-darkmode">
              <div>
                <span class="icon-moon moon" aria-hidden="true"></span>
                <span class="icon-sunny sun" aria-hidden="true"></span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

</header>

<main class="main-wrap" style="margin-top:4%">
    
  
  <article>
    <div class="l-content in-post">
        <div class="l-wrapper in-post  js-aos-wrapper" data-aos="fade-up" data-aos-delay="300">
          <div class="l-post-content  has-subscribe-form js-progress-content">
            <header class="m-heading">
              <h1 class="m-heading__title in-post">DenseNet -Densely Connected Convolutional Networks (CVPR 2017) ðŸ“‘</h1>
              <div class="m-heading__meta">
                  <a href="../tag/8k-views/index.html" class="m-heading__meta__tag">8k+ views</a>
                  <span class="m-heading__meta__divider" aria-hidden="true">â€¢</span>
                <span class="m-heading__meta__time">Nov 10, 2019</span>
              </div>
            </header>
            <div class="pos-relative js-post-content">
              <div class="m-share">
                <div class="m-share__content js-sticky">
                  <a href="https://www.youtube.com/playlist?list=PLKsk3K4Z-1AVwIzEi9pk-ayEh9uxdyweL" class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Youtube">
                    <span class="icon-youtube" aria-hidden="true"></span>
                  </a>
                  <a href="https://open.spotify.com/show/2eq1jD7V5K19aZUUJnIz5z" class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Spotify">
                    <span class="icon-spotify" aria-hidden="true"></span>
                  </a>
                  <button class="m-icon-button filled in-share progress js-scrolltop" aria-label="Scroll to top">
                    <span class="icon-arrow-top" aria-hidden="true"></span>
                    <svg aria-hidden="true">
                      <circle class="progress-ring__circle js-progress" fill="transparent" r="0"></circle>
                    </svg>
                  </button>
                </div>
              </div>
              <p>CVPR 2017, Best Paper Award winner</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*TeHVqikNc68QC98Vm9M98Q.gif" class="kg-image" alt loading="lazy"><figcaption>Dense connections</figcaption></figure><blockquote><strong>â€œSimple models and a lot of data trump more elaborate models based on less data. â€œâ€Šâ€”â€Š</strong>Peter Norvig</blockquote><h3 id="about-the-paper">About the paper</h3><p>â€˜<strong>Densely Connected Convolutional Networks</strong>â€™ received the <strong>Best Paper Award</strong> at the IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) <strong>2017</strong>. The paper can be read <a href="https://arxiv.org/pdf/1608.06993.pdf" rel="noopener">here</a>.</p><p>The primary author, <a href="http://www.gaohuang.net/" rel="noopener"><strong>Gao Huang</strong></a> has been a Postdoctoral Fellow at Cornell University and is currently working at Tsinghua University as an Assistant Professor. His research focuses on deep learning for computer vision.</p><h3 id="how-i-came-across-the-paper">How I came across the paper?</h3><p>I came across this paper while researching for neural network implementations that were focused on improving image quality (in terms of resolution or dynamic range) by reconstruction. Although this paper demonstrates the prowess of the architecture in image classification, the idea of dense connections has inspired optimisations in many other deep learning domains like image super-resolution, image segmentation, medical diagnosis etc.</p><h3 id="key-contributions-of-the-densenet-architecture">Key contributions of the DenseNet architecture</h3><ul><li>Alleviates <strong>vanishing gradient problem</strong></li><li>Stronger <strong>feature propagation</strong></li><li><strong>Feature reuse</strong></li><li><strong>Reduced parameter</strong> count</li></ul><blockquote><strong>Before you read: </strong><br>Understanding this post requires a basic understanding of deep learning concepts.</blockquote><h3 id="paper-review">Paper review</h3><p>The paper starts with talking about the <strong>vanishing gradient problemâ€Šâ€”â€Š</strong>about how, as networks get deeper, gradients arenâ€™t back-propagated sufficiently to the initial layers of the network. The gradients keep getting smaller as they move backwards into the network and as a result, the initial layers lose their capacity to learn the basic low-level features.</p><p>Several architectures have been developed to solve this problem. These includeâ€Šâ€”â€ŠResNets, Highway Networks, Fractal Nets, Stochastic depth networks.</p><figure class="kg-card kg-image-card"><img src="https://cdn-images-1.medium.com/max/800/1*MwxLN83uT8bgd4nGiR6JZQ.jpeg" class="kg-image" alt loading="lazy"></figure><p>Regardless of the architectural designs of these networks, they all try to create channels for information to flow between the initial layers and the final layers. DenseNets, with the same objective, create paths between the layers of the network.</p><h3 id="related-works">Related works</h3><ul><li>Highway networks (one of the first attempts at making training easy for deeper models)</li><li>ResNet (Bypassing connections by summation using identity mappings)</li><li>Stochastic depth (dropping layers randomly during training)</li><li>GoogLeNet (inception moduleâ€Šâ€”â€Šincreasing network width)</li><li>FractalNet</li><li>Network in Network (NIN)</li><li>Deeply Supervised Network (DSN)</li><li>Ladder Networks</li><li>Deeply-Fused Nets (DFNs)</li></ul><h3 id="dense-connections">Dense connections</h3><p>Following the feed-forward nature of the network, each layer in a dense block receives feature maps from all the preceding layers, and passes its output to all subsequent layers. Feature maps received from other layers are fused through <strong>concatenation</strong>, and not through summation (like in ResNets).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*StSq7XyHcuxUOfWuuALkdw.png" class="kg-image" alt loading="lazy"><figcaption>Concatenation of featureÂ maps</figcaption></figure><p>These connections form a dense circuit of pathways that allow <strong>better gradient-flow</strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*TeHVqikNc68QC98Vm9M98Q.gif" class="kg-image" alt loading="lazy"><figcaption>Dense connections</figcaption></figure><blockquote>Each layer has direct access to the gradients of the loss function and the original input signal.</blockquote><p>Because of these dense connections, the model requires fewer layers, as there is no need to learn redundant feature maps, allowing the <strong>collective knowledge </strong>(features learnt collectively by the network) to be reused. The proposed architecture has narrow layers, which provide state-of-the-art results for as low as 12 channel feature maps. Fewer and narrower layers means that the model has <strong>fewer parameters</strong> to learn, making them easier to train. The authors also talk about the importance of variation in input of layers as a result of concatenated feature maps, which prevents the model from over-fitting the training data.</p><figure class="kg-card kg-image-card"><img src="https://cdn-images-1.medium.com/max/800/1*04TJTANujOsauo3foe0zbw.jpeg" class="kg-image" alt loading="lazy"></figure><p>Many variants of the DenseNet model have been presented in the paper. I have opted to explain the concepts with their standard network (DenseNet-121).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*rkra9kVPl754-vjRGsOqvw.png" class="kg-image" alt loading="lazy"><figcaption>Some of the variants of the DenseNet architecture</figcaption></figure><h3 id="composite-function">Composite function</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/600/1*qA2rLVBRB-wZoI3nAEMdkA.png" class="kg-image" alt loading="lazy"><figcaption>Composite function</figcaption></figure><p>*Each CONV block in the network representations in the paper (and in the blog) corresponds to an operation of â€”</p><p><strong>BatchNormâ†’ReLUâ†’Conv*</strong></p><h3 id="dense-block">Dense block</h3><p>The concept of dense connections has been portrayed in dense blocks. A dense block comprises <em>n </em>dense layers. These dense layers are connected using a dense circuitry such that each dense layer receives feature maps from all preceding layers and passes itâ€™s feature maps to all subsequent layers. The dimensions of the features (width, height) stay the same in a dense block.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*ZfrliiHwn_L4kKcO61Oxgw.png" class="kg-image" alt loading="lazy"><figcaption><strong class="markup--strong markup--figure-strong">Dense block (DB) with six Dense LayersÂ (DL)</strong></figcaption></figure><h3 id="dense-layer">Dense layer</h3><p>Each dense-layer consists of 2 convolutional operations -</p><ul><li><strong>1 X 1 CONV </strong>(conventional conv operation for extracting features)</li><li><strong>3 X 3 CONV </strong>(bringing down the feature depth/channel count)</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*cRXqccOxYkZbWpfmyXzjog.png" class="kg-image" alt loading="lazy"><figcaption><strong class="markup--strong markup--figure-strong">Dense layer ofÂ DB-1</strong></figcaption></figure><p>The DenseNet-121 comprises of 6 such dense layers in a dense block. The depth of the output of each dense-layer is equal to the growth rate of the dense block.</p><h3 id="growth-rate-k-">Growth rate (k)</h3><p>This is a term youâ€™ll come across a lot in the paper. It is basically the number of channels output by a dense-layer (<em>1x1 conv â†’ 3x3 conv</em>). The authors have used a value of <em>k = 32</em> for the experiments. This means that the number of features received by a dense layer ( <em>l </em>) from itâ€™s preceding dense layer ( <em>l-1</em> ) is 32. This is referred to as the growth rate because after each layer, 32 channel features are concatenated and fed as input to the next layer.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*NIQenf9KTillNhYfuySfMw.png" class="kg-image" alt loading="lazy"><figcaption>Dense block with channel count (C) of features entering and exiting theÂ layers</figcaption></figure><h3 id="transition-layer">Transition layer</h3><p>At the end of each dense block, the number of feature-maps accumulates to a value ofâ€Šâ€”â€Š<em>input features + (number of dense layers x growth rate). </em>So for 64 channel features entering a dense block of 6 dense-layers of growth rate 32, the number of channels accumulated at the end of the block will beâ€Šâ€”â€Š<br>64 + (6 x 32) = 256. To bring down this channel count, a <strong>transition layer </strong>(or block) is added between two dense blocks. The transition layer consists of -</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/600/1*LoFEV57u5kCjsqZRX7EAKw.png" class="kg-image" alt loading="lazy"><figcaption><strong class="markup--strong markup--figure-strong">Transition layer/block</strong></figcaption></figure><ul><li><strong>1 X 1 CONV</strong> operation</li><li><strong>2 X 2 AVG POOL </strong>operation</li></ul><p>The <strong>1 X 1 CONV </strong>operation reduces the channel count to half.<br> The <strong>2 X 2 AVG POOL</strong> layer is responsible for downsampling the features in terms of the width and height.</p><h3 id="full-network">Full network</h3><p>As can be seen in the diagram below, the authors have chosen different number of dense layers for each of the three dense block.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*CE11_lfEz00aoOjLiw5sdw.png" class="kg-image" alt loading="lazy"><figcaption><strong class="markup--strong markup--figure-strong">Full DenseNet architecture</strong></figcaption></figure><h3 id="comparison-with-densenet">Comparison with DenseNet</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/600/1*cXAoIC_ig5R8nE4hKj2OeQ.png" class="kg-image" alt loading="lazy"><figcaption>ResNet DenseNet comparison</figcaption></figure><p>We can see that even with a reduced parameter count, the DenseNet model has a significantly lower validation error for the ResNet model with the same number of parameters. These experiments were carried out on both the models with hyper-parameters that suited ResNet better. The authors claim that DenseNet would perform better after extensive hyper-parameter searches.</p><blockquote>DenseNet-201 with 20M parameters model yields similar validation error as a 101-layer ResNet with more than 40M parameters.</blockquote><h3 id="inspecting-the-code">Inspecting the code</h3><p>I believe that going through the code makes it easier to understand the implementations of such architectures. Research papers (in the context of Deep Learning) can be difficult to understand because they are more about what drives the design decisions of a neural network. Inspecting the code (usually the network/model code) can reduce this complexity because sometimes itâ€™s just the implementation that we are interested in. Some people prefer first seeing the implementation and then trying to figure out the reasoning behind the design decisions of the network. Regardless, reading the code, before or after, always helps.</p><p>The code of the DenseNet implementation can be found <a href="https://github.com/liuzhuang13/DenseNet" rel="noopener">here</a>. Since I am more comfortable with PyTorch, Iâ€™ll try to explain the PyTorch implementation of the model which can be found <a href="https://github.com/gpleiss/efficient_densenet_pytorch" rel="noopener">here</a>. The most important file would be <strong>models/densenet.py</strong>, that hold the network architecture for DenseNet.</p><p>The code has been divided into these classes where each type of block is represented by a class.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*RgsliXFElnLQ5uh5ZCDBAg.png" class="kg-image" alt loading="lazy"><figcaption>Class hierarchy inÂ code</figcaption></figure><h3 id="dense-layer-1">Dense layer</h3><!--kg-card-begin: html--><script src="https://gist.github.com/mukulkhanna/1200979cc91e54f2e638872fd4680560.js"></script>
<!--kg-card-end: html--><p>The<strong> _DenseLayer </strong>class can be used to initialise the constituent operations of a dense layer â€”</p><p><strong>BatchNorm â†’ ReLU â†’ Conv (1X1) â†’ BatchNom â†’ ReLU â†’ Conv (3X3)</strong></p><p>The <strong>_bn_function_factory()</strong> function is responsible for concatenating the output of the previous layers to the current layer.</p><h3 id="denseblock"><strong>DenseBlock</strong></h3><!--kg-card-begin: html--><script src="https://gist.github.com/mukulkhanna/0783bc22b0b8f826ef92e1e7455c3075.js"></script><!--kg-card-end: html--><p>The _<strong>DenseBlock </strong>class houses a certain number of <strong>_DenseLayer</strong>s (<em>num_layers</em>).<br>This class is initialised from the <strong>DenseNet </strong>class depending on the number of dense blocks used in the network.</p><h3 id="transition-block">Transition Block</h3><!--kg-card-begin: html--><script src="https://gist.github.com/mukulkhanna/86feacfbdbbc4ad841adac0e00e4de75.js"></script><!--kg-card-end: html--><h3 id="densenet"><strong>DenseNet</strong></h3><p>Since this part of the code is a little too big to fit in this blog, Iâ€™ll just be using a part of the code that should help in getting the gist of the network.</p><!--kg-card-begin: html--><script src="https://gist.github.com/mukulkhanna/2238b561aca1c29878310fe322f1ba54.js"></script><!--kg-card-end: html--><p>I found this image online and it has helped me understand the network better.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn-images-1.medium.com/max/800/1*vIZhPImFr9Gjpx6ZB7IOJg.png" class="kg-image" alt="Image result for densenet architecture" loading="lazy"><figcaption><a href="https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a" data-href="https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Source</a></figcaption></figure><h3 id="other-works-inspired-from-this-paper">Other works inspired from this paper</h3><ul><li><a href="https://arxiv.org/abs/1802.08797" rel="noopener">Residual Dense Network for Image Super-Resolution</a> (2018)</li></ul><figure class="kg-card kg-image-card"><img src="https://cdn-images-1.medium.com/max/800/1*6NS5NPZoU3iQXIJOu6jruQ.png" class="kg-image" alt loading="lazy"></figure><ul><li><a href="http://www.statnlp.org/research/lg/zhijiang_zhangyan19tacl-gcn.pdf" rel="noopener">Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning</a> (2019)</li></ul><figure class="kg-card kg-image-card"><img src="https://cdn-images-1.medium.com/max/800/1*pa45Gjp8H1D9NnXJE6Vypw.png" class="kg-image" alt loading="lazy"></figure><h3 id="conclusion">Conclusion</h3><p>DenseNet is a network that portrays the importance of having dense connections in a network using dense blocks. This helps in feature-reuse, better gradient flow, reduced parameter count and better transmission of features across the network. Such an implementation can help in training deeper networks using less computational resources and with better results.<br></p>
            </div>
          </div>
        </div>
        <section class="m-recommended">
          <div class="l-wrapper in-recommended">
            <h3 class="m-section-title in-recommended"><b>Recommended for you</b></h3>
            <div class="m-recommended-articles">
              <div class="m-recommended-slider glide js-recommended-slider">
                <div class="glide__track" data-glide-el="track">
                  <div class="glide__slides">
                    
    <div class="m-recommended-slider__item glide__slide">
  <article class="m-article-card  post tag-nlp tag-deep-learning tag-chatbots tag-open-source tag-podcast">
    <div class="m-article-card__picture">
      <a href="../dnn-2-conversational-ai-nlp-huggingface-thomas-wolf/index.html" class="m-article-card__picture-link" aria-hidden="true" tabindex="-1"></a>
        <img class="m-article-card__picture-background" src="../content/images/size/w600/2020/10/Podcast-thumbnails-2.002.jpeg" loading="lazy" alt="">
    </div>
      <div class="m-article-card__info">
        <a href="../tag/nlp/index.html" class="m-article-card__tag">NLP</a>
      <a href="../dnn-2-conversational-ai-nlp-huggingface-thomas-wolf/index.html" class="m-article-card__info-link" aria-label="DNN 2: Conversational AI, NLP &amp; HuggingFace ðŸ¤— // Thomas Wolf">
        <div>
          <h2 class="m-article-card__title js-article-card-title " title="DNN 2: Conversational AI, NLP &amp; HuggingFace ðŸ¤— // Thomas Wolf">
            DNN 2: Conversational AI, NLP &amp; HuggingFace ðŸ¤— // Thomas Wolf
          </h2>
        </div>
        <div class="m-article-card__timestamp">
          <span>a year ago</span>
          <span>â€¢</span>
          <span>1 min read</span>
        </div>
      </a>
    </div>
  </article>
    </div>
    <div class="m-recommended-slider__item glide__slide">
  <article class="m-article-card  post tag-computer-vision tag-machine-learning tag-human-computer-interaction tag-podcast">
    <div class="m-article-card__picture">
      <a href="../dnn-9-computer-vision-machine-learning-inside-the-car/index.html" class="m-article-card__picture-link" aria-hidden="true" tabindex="-1"></a>
        <img class="m-article-card__picture-background" src="../content/images/size/w600/2020/10/Podcast-thumbnails-2.009.jpeg" loading="lazy" alt="">
    </div>
      <div class="m-article-card__info">
        <a href="../tag/computer-vision/index.html" class="m-article-card__tag">Computer Vision</a>
      <a href="../dnn-9-computer-vision-machine-learning-inside-the-car/index.html" class="m-article-card__info-link" aria-label="DNN 9: NVIDIA's AI Co-Pilot , Computer Vision &amp; ML Inside The Car // Shalini De Mello">
        <div>
          <h2 class="m-article-card__title js-article-card-title " title="DNN 9: NVIDIA's AI Co-Pilot , Computer Vision &amp; ML Inside The Car // Shalini De Mello">
            DNN 9: NVIDIA's AI Co-Pilot , Computer Vision &amp; ML Inside The Car // Shalini De Mello
          </h2>
        </div>
        <div class="m-article-card__timestamp">
          <span>a year ago</span>
          <span>â€¢</span>
          <span>1 min read</span>
        </div>
      </a>
    </div>
  </article>
    </div>
    <div class="m-recommended-slider__item glide__slide">
  <article class="m-article-card  post tag-computer-vision tag-deep-learning tag-machine-learning tag-podcast">
    <div class="m-article-card__picture">
      <a href="../dnn-8/index.html" class="m-article-card__picture-link" aria-hidden="true" tabindex="-1"></a>
        <img class="m-article-card__picture-background" src="../content/images/size/w600/2020/10/Podcast-thumbnails-2.008.jpeg" loading="lazy" alt="">
    </div>
      <div class="m-article-card__info">
        <a href="../tag/computer-vision/index.html" class="m-article-card__tag">Computer Vision</a>
      <a href="../dnn-8/index.html" class="m-article-card__info-link" aria-label="DNN 8: Computer Vision &amp; ML Research, Super SloMo // Varun Jampani">
        <div>
          <h2 class="m-article-card__title js-article-card-title " title="DNN 8: Computer Vision &amp; ML Research, Super SloMo // Varun Jampani">
            DNN 8: Computer Vision &amp; ML Research, Super SloMo // Varun Jampani
          </h2>
        </div>
        <div class="m-article-card__timestamp">
          <span>a year ago</span>
          <span>â€¢</span>
          <span>1 min read</span>
        </div>
      </a>
    </div>
  </article>
    </div>
                  </div>
                </div>
                <div data-glide-el="controls" class="glide__arrows js-controls">
                  <button data-glide-dir="&lt;" class="m-icon-button filled in-recommended-articles glide-prev" aria-label="Previous">
                    <span class="icon-arrow-left" aria-hidden="true"></span>
                  </button>
                  <button data-glide-dir="&gt;" class="m-icon-button filled in-recommended-articles glide-next" aria-label="Next">
                    <span class="icon-arrow-right" aria-hidden="true"></span>
                  </button>
                </div>
              </div>
            </div>
          </div>
        </section>
    </div>
  </article>
</main>



    
<div class="m-search js-search" role="dialog" aria-modal="true" aria-label="Search">
  <button class="m-icon-button outlined as-close-search js-close-search" aria-label="Close search">
    <span class="icon-close" aria-hidden="true"></span>
  </button>
  <div class="m-search__content">
    <form class="m-search__form">
      <div class="pos-relative">
        <span class="icon-search m-search-icon" aria-hidden="true"></span>
        <label for="search-input" class="sr-only">
          Type to search
        </label>
        <input id="search-input" type="text" class="m-input in-search js-input-search" placeholder="Type to search">
      </div>
    </form>
    <div class="js-search-results hide"></div>
    <p class="m-not-found align-center hide js-no-results">
      No results for your search, please try with something else.
    </p>
  </div>
</div>

    
<footer class="m-footer">
  <div class="m-footer__content">
    <p class="m-footer-copyright">
      <span>Mukul Khanna Â© 2021</span>
      <span>Â  â€¢ Â </span>
      <span>Published w/ <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a></span>
    </p>

    <nav class="m-footer-social">
        <a href="https://www.youtube.com/channel/UC66w1T4oMv66Jn1LR5CW2yg" target="_blank" rel="noopener" aria-label="Youtube">
          <span class="icon-youtube" aria-hidden="true"></span>
        </a>
        <a href="https://twitter.com/mkulkhanna" target="_blank" rel="noopener" aria-label="Twitter">
          <span class="icon-twitter" aria-hidden="true"></span>
        </a>
      <a href="http://localhost:2368/rss" aria-label="RSS">
        <span class="icon-rss" aria-hidden="true"></span>
      </a>
    </nav>
  </div>
</footer>

    <div class="m-alert success subscribe js-alert" data-notification="subscribe">
  Great! You've successfully subscribed.
  <button class="m-alert__close js-notification-close" aria-label="Close">
    <span class="icon-close"></span>
  </button>
</div>

<div class="m-alert success signup js-alert" data-notification="signup">
  Great! Next, complete checkout for full access.
  <button class="m-alert__close js-notification-close" aria-label="Close">
    <span class="icon-close"></span>
  </button>
</div>

<div class="m-alert success signin js-alert" data-notification="signin">
  Welcome back! You've successfully signed in.
  <button class="m-alert__close js-notification-close" aria-label="Close">
    <span class="icon-close"></span>
  </button>
</div>

<div class="m-alert success checkout js-alert" data-notification="checkout">
  Success! Your account is fully activated, you now have access to all content.
  <button class="m-alert__close js-notification-close" aria-label="Close">
    <span class="icon-close"></span>
  </button>
</div>
    <script crossorigin="anonymous" src="https://polyfill.io/v3/polyfill.min.js?features=IntersectionObserver%2CPromise%2CArray.prototype.includes%2CString.prototype.endsWith%2CString.prototype.startsWith%2CObject.assign%2CNodeList.prototype.forEach"></script>
    <script defer src="../assets/js/manifest.js?v=decde706a5"></script>
    <script defer src="../assets/js/vendor/content-api.min.js?v=decde706a5"></script>
    <script defer src="../assets/js/vendor.js?v=decde706a5"></script>
    <script defer src="../assets/js/app.js?v=decde706a5"></script>

      <script defer src="../assets/js/post.js?v=decde706a5"></script>


    <!-- prism.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-markup.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-css.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
  </body>
</html>